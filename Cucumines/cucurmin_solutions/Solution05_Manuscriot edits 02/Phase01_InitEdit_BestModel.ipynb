{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 10.2 s\n",
      "Wall time: 24.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem, MACCSkeys, Descriptors\n",
    "\n",
    "# Defining the SMILES strings for the cucumin varients\n",
    "curcumin_variants = (\n",
    "    \"COc3cc(OC)c(C/C=C/C2=CC(/C=C/Cc1c(OC)cc(OC)cc1OC)=[O+][B-](F)(F)O2)c(OC)c3\",\n",
    "    \"COc3ccc(C/C=C/C2=[O+][B-](F)(F)OC(/C=C/Cc1c(OC)cc(OC)cc1OC)=C2)cc3\",\n",
    "    \"COc3ccc(C/C=C/C2=CC(/C=C/Cc1ccc(OC)cc1OC)=[O+][B-](F)(F)O2)c(OC)c3\",\n",
    "    \"COc5ccc(C/C=C/C4=[O+][B-](F)(F)OC(/C=C/Cc2c1ccccc1cc3ccccc23)=C4)cc5\",\n",
    "    \"COc3ccc(OC)c(C/C=C/C2=CC(/C=C/Cc1cc(OC)ccc1OC)=[O+][B-](F)(F)O2)c3\",\n",
    "    \"COc3cc(C/C=C/C2=CC(/C=C/Cc1ccc(O)c(OC)c1)=[O+][B-](F)(F)O2)ccc3O\",\n",
    "    \"CN(C)c3ccc(C/C=C/C2=CC(/C=C/Cc1ccc(N(C)C)cc1)=[O+][B-](F)(F)O2)cc3\",\n",
    "    \"N#Cc3ccc(C/C=C/C2=[O+][B-](F)(F)OC(/C=C/Cc1ccccc1)=C2)cc3\",\n",
    "    \"COc6ccc(C/C=C/C5=CC(/C=C/Cc1cc2ccc3cccc4ccc(c1)c2c34)=[O+][B-](F)(F)O5)cc6\",\n",
    "    \"COc4ccc(C/C=C/C3=CC(/C=C/Cc1ccc(OC)c2ccccc12)=[O+][B-](F)(F)O3)c5ccccc45\",\n",
    "    \"CN(C)c4ccc(C/C=C/C3=CC(/C=C/Cc1ccc(N(C)C)c2ccccc12)=[O+][B-](F)(F)O3)c5ccccc45\",\n",
    "    \"N#Cc3ccc(C/C=C/C2=CC(/C=C/Cc1ccc(C#N)cc1)=[O+][B-](F)(F)O2)cc3\",\n",
    "    \"CCCCN(CCCC)c3ccc(C/C=C/C2=CC(/C=C/Cc1ccc(N(CCCC)CCCC)cc1)=[O+][B-](F)(F)O2)cc3\",\n",
    "    \"COc3ccc(C/C=C/C2=CC(/C=C/Cc1ccc(C#N)cc1)=[O+][B-](F)(F)O2)cc3\",\n",
    "    \"CN5/C(=C\\C\\C=C\\C3=CC(/C=C/C/C=C/2N(C)c1ccccc1C2(C)C)=[O+][B-](F)(F)O3)C(C)(C)c4ccccc45\",\n",
    "    \"COc3ccc(C/C=C/C2=[O+][B-](F)(F)OC(/C=C/Cc1ccc(SC)cc1)=C2)cc3\",\n",
    "    \"CSc3ccc(C/C=C/C2=CC(/C=C/Cc1ccc(SC)cc1)=[O+][B-](F)(F)O2)cc3\",\n",
    "    \"COc3ccc(C/C=C/C2=CC(/C=C/Cc1ccc(N(C)C)cc1)=[O+][B-](F)(F)O2)cc3\",\n",
    "    \"COc1ccccc1C/C=C/C3=CC(/C=C/Cc2ccccc2OC)=[O+][B-](F)(F)O3\",\n",
    "    \"CCCCCC(CC)c5ccc(c4ccc(C/C=C/C3=CC(/C=C/Cc2ccc(c1ccc(C(CC)CCCCC)s1)s2)=[O+][B-](F)(F)O3)s4)s5\"\n",
    ")\n",
    "\n",
    "molecule_names = ['2-ADMeO3', '3-MR83a', 'AD-10', 'AD-1013', 'AD-1022', 'AD-11', 'AD-14-Moore', 'AD-16-DMF', 'AD-18', 'AD-24', 'AD-25', 'AD-3', 'AD-35', 'AD-4', 'AD-48', 'AD-5', 'AD-6', 'AD-7', 'AD-9', 'YD-30']\n",
    "homo_lumo_gap = [3.077, 3.072, 3.259, 2.625, 2.938, 2.946, 2.811, 3.231, 2.735, 2.878, 2.686, 3.215, 2.77, 3.001, 2.702, 2.97, 2.89, 2.859, 3.137, 2.525]\n",
    "\n",
    "molecules = [Chem.MolFromSmiles(smiles) for smiles in curcumin_variants]\n",
    "mws = [round(Descriptors.MolWt(mol),3) for mol in molecules]\n",
    "logp = [Descriptors.MolLogP(mol) for mol in molecules]\n",
    "\n",
    "# Create the initial DataFrame\n",
    "data = {\n",
    "    'Molecule': molecule_names,\n",
    "    'Molecular Weight': mws,\n",
    "    'LogP': logp,\n",
    "    'Homo-Lumo Gap (eV)': homo_lumo_gap,\n",
    "    'Smiles': curcumin_variants\n",
    "}\n",
    "curcumin_df = pd.DataFrame(data)\n",
    "curcumin_df['mol'] = curcumin_df['Smiles'].apply(Chem.MolFromSmiles)\n",
    "\n",
    "# Harvard OPV dataset import\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/AjStephan/havard-smile-opv/main/Non-fullerene%20small-molecules%20acceptors.csv')\n",
    "opv_df = data.drop(columns=[\n",
    "    'index', 'inchikey', 'HOMO_calc', 'LUMO_calc', 'LUMO_calib', 'LUMO_calib_stds',\n",
    "    'HOMO_calib', 'HOMO_calib_stds','GAP_calc', 'molW', 'PCE_calc', 'Voc_calc', 'Jsc_calc',\n",
    "    'FF_calc', 'EQE_calc', 'PCE_calib', 'Voc_calib', 'Jsc_calib', 'FF_calib',\n",
    "    'EQE_calib', 'PCE_cdiff', 'PCE_calib_plus'], axis=1)\n",
    "\n",
    "opv_df['mol'] = opv_df['smiles'].apply(Chem.MolFromSmiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing morgan fingerprints\n",
      "Finished processing maccs fingerprints\n",
      "Finished processing atom_pair fingerprints\n",
      "Finished processing fcfp fingerprints\n",
      "CPU times: total: 3min 34s\n",
      "Wall time: 3min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, MACCSkeys, rdMolDescriptors\n",
    "from rdkit.DataStructs import ExplicitBitVect\n",
    "import numpy as np\n",
    "\n",
    "# Functions to generate fingerprints\n",
    "def generate_morgan_fingerprint(mol, radius=2, nBits=2048):\n",
    "    return AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=nBits)\n",
    "\n",
    "def generate_maccs166_fingerprint(mol):\n",
    "    return MACCSkeys.GenMACCSKeys(mol)\n",
    "\n",
    "def generate_atom_pair_fingerprint(mol, nBits=2048):\n",
    "    fp = rdMolDescriptors.GetAtomPairFingerprint(mol)\n",
    "    return convert_to_bit_vector(fp, nBits)\n",
    "\n",
    "def generate_fcfp_fingerprint(mol, radius=2, nBits=2048):\n",
    "    return AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=nBits, useFeatures=True)\n",
    "\n",
    "# Convert any fingerprint to a bit vector\n",
    "def convert_to_bit_vector(fp, nBits=2048):\n",
    "    bit_vector = ExplicitBitVect(nBits)\n",
    "    for bit in fp.GetNonzeroElements().keys():\n",
    "        bit_vector.SetBit(bit % nBits)\n",
    "    return bit_vector\n",
    "\n",
    "# Function to add fingerprint to dataframe\n",
    "def add_fingerprint_to_df(df, fingerprint_func, fp_name):\n",
    "    df[fp_name] = df['mol'].apply(fingerprint_func)\n",
    "    return df\n",
    "\n",
    "# Function to split fingerprints into separate bit columns\n",
    "def split_fingerprint_bits(df, fp_column, prefix):\n",
    "    bit_array = np.array([list(fp) for fp in df[fp_column].values])\n",
    "    bit_columns = pd.DataFrame(bit_array, columns=[f'{prefix}_{i}' for i in range(bit_array.shape[1])])\n",
    "    df = pd.concat([df.drop(columns=[fp_column]), bit_columns], axis=1)\n",
    "    return df\n",
    "\n",
    "# Assuming opv_df is already defined and 'mol' column has been created\n",
    "# List of fingerprint generation functions and names\n",
    "fingerprint_functions = [\n",
    "    (generate_morgan_fingerprint, 'morgan_fp', 'morgan'),\n",
    "    (generate_maccs166_fingerprint, 'maccs_fp', 'maccs'),\n",
    "    (generate_atom_pair_fingerprint, 'atom_pair_fp', 'atom_pair'),\n",
    "    (generate_fcfp_fingerprint, 'fcfp_fp', 'fcfp')\n",
    "]\n",
    "\n",
    "# List to store resulting dataframes\n",
    "resulting_dfs = []\n",
    "\n",
    "# Generate and store dataframes with fingerprints\n",
    "for fp_func, fp_name, prefix in fingerprint_functions:\n",
    "    df_copy = opv_df.copy()\n",
    "    df_copy = add_fingerprint_to_df(df_copy, fp_func, fp_name)\n",
    "    df_copy = split_fingerprint_bits(df_copy, fp_name, prefix)\n",
    "    resulting_dfs.append(df_copy)\n",
    "    print(f'Finished processing {prefix} fingerprints')\n",
    "\n",
    "# The resulting_dfs list now contains your four dataframes with split fingerprint columns\n",
    "opv_df_morgan = resulting_dfs[0]\n",
    "opv_df_maccs = resulting_dfs[1]\n",
    "opv_df_atom_pair = resulting_dfs[2]\n",
    "opv_df_fcfp = resulting_dfs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3038\n",
      "[LightGBM] [Info] Number of data points in the train set: 38442, number of used features: 1519\n",
      "[LightGBM] [Info] Start training from score 2.805288\n",
      "Finished processing Morgan fingerprints with LightGBM model:\n",
      "Finished processing Morgan fingerprints with Bayesian Ridge model:\n",
      "Finished processing Morgan fingerprints with KNN Regressor model:\n",
      "Finished processing Morgan fingerprints with Passive Aggressive model:\n",
      "Finished processing Morgan fingerprints\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 212\n",
      "[LightGBM] [Info] Number of data points in the train set: 38442, number of used features: 106\n",
      "[LightGBM] [Info] Start training from score 2.805288\n",
      "Finished processing MACCS fingerprints with LightGBM model:\n",
      "Finished processing MACCS fingerprints with Bayesian Ridge model:\n",
      "Finished processing MACCS fingerprints with KNN Regressor model:\n",
      "Finished processing MACCS fingerprints with Passive Aggressive model:\n",
      "Finished processing MACCS fingerprints\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012223 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 644\n",
      "[LightGBM] [Info] Number of data points in the train set: 38442, number of used features: 322\n",
      "[LightGBM] [Info] Start training from score 2.805288\n",
      "Finished processing Atom Pair fingerprints with LightGBM model:\n",
      "Finished processing Atom Pair fingerprints with Bayesian Ridge model:\n",
      "Finished processing Atom Pair fingerprints with KNN Regressor model:\n",
      "Finished processing Atom Pair fingerprints with Passive Aggressive model:\n",
      "Finished processing Atom Pair fingerprints\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1710\n",
      "[LightGBM] [Info] Number of data points in the train set: 38442, number of used features: 855\n",
      "[LightGBM] [Info] Start training from score 2.805288\n",
      "Finished processing FCFP fingerprints with LightGBM model:\n",
      "Finished processing FCFP fingerprints with Bayesian Ridge model:\n",
      "Finished processing FCFP fingerprints with KNN Regressor model:\n",
      "Finished processing FCFP fingerprints with Passive Aggressive model:\n",
      "Finished processing FCFP fingerprints\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fingerprint Type</th>\n",
       "      <th>Regression Model</th>\n",
       "      <th>R² Score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morgan</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.869593</td>\n",
       "      <td>0.220259</td>\n",
       "      <td>0.160347</td>\n",
       "      <td>0.048514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Morgan</td>\n",
       "      <td>Bayesian Ridge</td>\n",
       "      <td>0.845130</td>\n",
       "      <td>0.240031</td>\n",
       "      <td>0.175279</td>\n",
       "      <td>0.057615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Morgan</td>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>0.822717</td>\n",
       "      <td>0.256813</td>\n",
       "      <td>0.177070</td>\n",
       "      <td>0.065953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Morgan</td>\n",
       "      <td>Passive Aggressive</td>\n",
       "      <td>0.769488</td>\n",
       "      <td>0.292840</td>\n",
       "      <td>0.221765</td>\n",
       "      <td>0.085755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MACCS</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.748884</td>\n",
       "      <td>0.305647</td>\n",
       "      <td>0.231771</td>\n",
       "      <td>0.093420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MACCS</td>\n",
       "      <td>Bayesian Ridge</td>\n",
       "      <td>0.589402</td>\n",
       "      <td>0.390834</td>\n",
       "      <td>0.301463</td>\n",
       "      <td>0.152751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MACCS</td>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>0.730760</td>\n",
       "      <td>0.316485</td>\n",
       "      <td>0.232920</td>\n",
       "      <td>0.100163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MACCS</td>\n",
       "      <td>Passive Aggressive</td>\n",
       "      <td>0.128132</td>\n",
       "      <td>0.569520</td>\n",
       "      <td>0.453692</td>\n",
       "      <td>0.324353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Atom Pair</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.668414</td>\n",
       "      <td>0.351222</td>\n",
       "      <td>0.256845</td>\n",
       "      <td>0.123357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Atom Pair</td>\n",
       "      <td>Bayesian Ridge</td>\n",
       "      <td>0.477364</td>\n",
       "      <td>0.440944</td>\n",
       "      <td>0.332171</td>\n",
       "      <td>0.194431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Atom Pair</td>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>0.659303</td>\n",
       "      <td>0.356015</td>\n",
       "      <td>0.248907</td>\n",
       "      <td>0.126747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Atom Pair</td>\n",
       "      <td>Passive Aggressive</td>\n",
       "      <td>0.267713</td>\n",
       "      <td>0.521945</td>\n",
       "      <td>0.407545</td>\n",
       "      <td>0.272426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FCFP</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.853608</td>\n",
       "      <td>0.233369</td>\n",
       "      <td>0.171052</td>\n",
       "      <td>0.054461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FCFP</td>\n",
       "      <td>Bayesian Ridge</td>\n",
       "      <td>0.810251</td>\n",
       "      <td>0.265689</td>\n",
       "      <td>0.196491</td>\n",
       "      <td>0.070591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FCFP</td>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>0.833220</td>\n",
       "      <td>0.249089</td>\n",
       "      <td>0.176088</td>\n",
       "      <td>0.062045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FCFP</td>\n",
       "      <td>Passive Aggressive</td>\n",
       "      <td>0.672027</td>\n",
       "      <td>0.349304</td>\n",
       "      <td>0.267089</td>\n",
       "      <td>0.122013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fingerprint Type    Regression Model  R² Score      RMSE       MAE  \\\n",
       "0            Morgan            LightGBM  0.869593  0.220259  0.160347   \n",
       "1            Morgan      Bayesian Ridge  0.845130  0.240031  0.175279   \n",
       "2            Morgan       KNN Regressor  0.822717  0.256813  0.177070   \n",
       "3            Morgan  Passive Aggressive  0.769488  0.292840  0.221765   \n",
       "4             MACCS            LightGBM  0.748884  0.305647  0.231771   \n",
       "5             MACCS      Bayesian Ridge  0.589402  0.390834  0.301463   \n",
       "6             MACCS       KNN Regressor  0.730760  0.316485  0.232920   \n",
       "7             MACCS  Passive Aggressive  0.128132  0.569520  0.453692   \n",
       "8         Atom Pair            LightGBM  0.668414  0.351222  0.256845   \n",
       "9         Atom Pair      Bayesian Ridge  0.477364  0.440944  0.332171   \n",
       "10        Atom Pair       KNN Regressor  0.659303  0.356015  0.248907   \n",
       "11        Atom Pair  Passive Aggressive  0.267713  0.521945  0.407545   \n",
       "12             FCFP            LightGBM  0.853608  0.233369  0.171052   \n",
       "13             FCFP      Bayesian Ridge  0.810251  0.265689  0.196491   \n",
       "14             FCFP       KNN Regressor  0.833220  0.249089  0.176088   \n",
       "15             FCFP  Passive Aggressive  0.672027  0.349304  0.267089   \n",
       "\n",
       "         MSE  \n",
       "0   0.048514  \n",
       "1   0.057615  \n",
       "2   0.065953  \n",
       "3   0.085755  \n",
       "4   0.093420  \n",
       "5   0.152751  \n",
       "6   0.100163  \n",
       "7   0.324353  \n",
       "8   0.123357  \n",
       "9   0.194431  \n",
       "10  0.126747  \n",
       "11  0.272426  \n",
       "12  0.054461  \n",
       "13  0.070591  \n",
       "14  0.062045  \n",
       "15  0.122013  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import BayesianRidge, PassiveAggressiveRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import numpy as np\n",
    "\n",
    "models = {\n",
    "    'LightGBM': LGBMRegressor(),\n",
    "    'Bayesian Ridge': BayesianRidge(),\n",
    "    'KNN Regressor': KNeighborsRegressor(),\n",
    "    'Passive Aggressive': PassiveAggressiveRegressor()\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, df in enumerate([opv_df_morgan, opv_df_maccs, opv_df_atom_pair, opv_df_fcfp]):\n",
    "    fingerprint_type = ['Morgan', 'MACCS', 'Atom Pair', 'FCFP'][i]\n",
    "    \n",
    "    X = df.iloc[:, 3:]  \n",
    "    y = df[\"GAP_calib\"] \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "        print(f'Finished processing {fingerprint_type} fingerprints with {model_name} model:')\n",
    "        \n",
    "        results.append({\n",
    "            'Fingerprint Type': fingerprint_type,\n",
    "            'Regression Model': model_name,\n",
    "            'R² Score': r2,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'MSE': mse\n",
    "        })\n",
    "    print(f'Finished processing {fingerprint_type} fingerprints')\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting grid search for LightGBM model with Morgan fingerprints...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052483 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3038\n",
      "[LightGBM] [Info] Number of data points in the train set: 38442, number of used features: 1519\n",
      "[LightGBM] [Info] Start training from score 2.805288\n",
      "Finished processing Morgan fingerprints with optimized LightGBM model\n",
      "Starting grid search for Bayesian Ridge model with Morgan fingerprints...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStarting grid search for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m model with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfingerprint_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fingerprints...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     50\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(model, param_grids[model_name], cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 51\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Get the best model after grid search\u001b[39;00m\n\u001b[0;32m     54\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32mc:\\Users\\Chamod Peiris\\Documents\\GitHub\\Curcumin_BendGap_Cheminfo\\.venv\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Chamod Peiris\\Documents\\GitHub\\Curcumin_BendGap_Cheminfo\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Chamod Peiris\\Documents\\GitHub\\Curcumin_BendGap_Cheminfo\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Chamod Peiris\\Documents\\GitHub\\Curcumin_BendGap_Cheminfo\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Chamod Peiris\\Documents\\GitHub\\Curcumin_BendGap_Cheminfo\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Chamod Peiris\\Documents\\GitHub\\Curcumin_BendGap_Cheminfo\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Chamod Peiris\\Documents\\GitHub\\Curcumin_BendGap_Cheminfo\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Chamod Peiris\\Documents\\GitHub\\Curcumin_BendGap_Cheminfo\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import BayesianRidge, PassiveAggressiveRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Define parameter grids for each model\n",
    "param_grids = {\n",
    "    'LightGBM': {\n",
    "        'num_leaves': [31, 50],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'n_estimators': [100, 200]\n",
    "    },\n",
    "    'Bayesian Ridge': {\n",
    "        'alpha_1': [1e-6, 1e-4],\n",
    "        'alpha_2': [1e-6, 1e-4],\n",
    "        'lambda_1': [1e-6, 1e-4],\n",
    "        'lambda_2': [1e-6, 1e-4]\n",
    "    },\n",
    "    'KNN Regressor': {\n",
    "        'n_neighbors': [3, 5, 7],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': [1, 2]\n",
    "    },\n",
    "    'Passive Aggressive': {\n",
    "        'C': [0.01, 0.1, 1],\n",
    "        'max_iter': [1000, 2000],\n",
    "        'tol': [1e-4, 1e-3]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize an empty list to store the optimized results\n",
    "optimized_results = []\n",
    "\n",
    "# Iterate over the four dataframes\n",
    "for i, df in enumerate([opv_df_morgan, opv_df_maccs, opv_df_atom_pair, opv_df_fcfp]):\n",
    "    fingerprint_type = ['Morgan', 'MACCS', 'Atom Pair', 'FCFP'][i]\n",
    "    \n",
    "    X = df.iloc[:, 3:]  # Features\n",
    "    y = df[\"GAP_calib\"]  # Target variable\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    # Perform grid search for each model\n",
    "    for model_name, model in models.items():\n",
    "        print(f'Starting grid search for {model_name} model with {fingerprint_type} fingerprints...')\n",
    "        \n",
    "        grid_search = GridSearchCV(model, param_grids[model_name], cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Get the best model after grid search\n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        # Make predictions using the optimized model\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        \n",
    "        # Append the results to the optimized_results list\n",
    "        optimized_results.append({\n",
    "            'Fingerprint Type': fingerprint_type,\n",
    "            'Regression Model': model_name,\n",
    "            'Best Parameters': grid_search.best_params_,\n",
    "            'R² Score': r2,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'MSE': mse\n",
    "        })\n",
    "        \n",
    "        print(f'Finished processing {fingerprint_type} fingerprints with optimized {model_name} model')\n",
    "\n",
    "optimized_results_df = pd.DataFrame(optimized_results)\n",
    "optimized_results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
